# Accelerate-Inference-of-Sparse-Transformer-Models-with-OpenVINO-
The tutorial downloads a BERT-base model optimized for SST2 datasets using Optimum-Intel, showcasing its inference performance on Scalable Processors using Sparse Weight Decompression.
